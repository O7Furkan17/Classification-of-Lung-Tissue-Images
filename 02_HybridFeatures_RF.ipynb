{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, models\n",
    "from torchvision.models import resnet50\n",
    "from skimage.feature import local_binary_pattern, graycomatrix, graycoprops\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import pywt\n",
    "import cv2\n",
    "from keras.applications.resnet import preprocess_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = r'Dataset\\lung_colon_image_set\\lung_image_sets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "classes = ['lung_aca', 'lung_n', 'lung_scc']\n",
    "\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "for label, cls in enumerate(classes):\n",
    "    cls_folder = os.path.join(image_folder, cls)\n",
    "    for image_name in os.listdir(cls_folder):\n",
    "        image_paths.append(os.path.join(cls_folder, image_name))\n",
    "        labels.append(label)\n",
    "\n",
    "\n",
    "train_paths, test_paths, train_labels, test_labels = train_test_split(image_paths, labels, test_size=0.2, random_state=48)\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = CustomDataset(train_paths, train_labels, transform=transform)\n",
    "test_dataset = CustomDataset(test_paths, test_labels, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Görüntü Ön İşleme: Histogram Eşitleme\n",
    "def histogram_equalization(image):\n",
    "    if len(image.shape) == 3:  # RGB görüntü\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    return cv2.equalizeHist(image)\n",
    "\n",
    "# 2. DWT (Discrete Wavelet Transform)\n",
    "def dwt_features(image):\n",
    "    coeffs = pywt.dwt2(image, 'db1')\n",
    "    cA, (cH, cV, cD) = coeffs\n",
    "    return cA.flatten()  # Ana bileşenleri döndür\n",
    "\n",
    "# 3. GLCM Özellik Çıkarma\n",
    "def glcm_features(image):\n",
    "    # Görüntüyü uint8 formatına dönüştür\n",
    "    image_np = (image.numpy() * 255).astype(np.uint8)\n",
    "    glcm = graycomatrix(image_np, distances=[1], angles=[0], levels=256, symmetric=True, normed=True)\n",
    "    contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
    "    dissimilarity = graycoprops(glcm, 'dissimilarity')[0, 0]\n",
    "    homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]\n",
    "    energy = graycoprops(glcm, 'energy')[0, 0]\n",
    "    return [contrast, dissimilarity, homogeneity, energy]\n",
    "# 4. LBP (Local Binary Pattern)\n",
    "def lbp_features(image):\n",
    "    # Görüntüyü numpy dizisine ve uint8 veri tipine dönüştür\n",
    "    image_np = (image.numpy() * 255).astype(np.uint8)\n",
    "    # Local Binary Pattern işlemi\n",
    "    lbp = local_binary_pattern(image_np, P=8, R=1, method=\"uniform\")\n",
    "    # Histogram çıkart ve döndür\n",
    "    return np.histogram(lbp, bins=np.arange(0, 11), density=True)[0]\n",
    "\n",
    "\n",
    "# 5. CNN Tabanlı Özellik Çıkarma (ResNet-50)\n",
    "def cnn_features(image):\n",
    "    model = resnet50(weights='imagenet', include_top=False, pooling='avg')\n",
    "    image_resized = cv2.resize(image, (224, 224))\n",
    "    image_preprocessed = preprocess_input(np.expand_dims(image_resized, axis=0))\n",
    "    features = model.predict(image_preprocessed)\n",
    "    return features.flatten()\n",
    "\n",
    "# 6. PCA ile Özellik Boyutunu Küçültme\n",
    "def apply_pca(features, n_components=500):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    return pca.fit_transform(features)\n",
    "\n",
    "def extract_features(loader):\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    for images, batch_labels in loader:\n",
    "        for img, label in zip(images, batch_labels):\n",
    "            img = img.permute(1, 2, 0).mean(dim=-1)  # RGB -> Grayscale\n",
    "            \n",
    "            dwt_feat = dwt_features(img)\n",
    "            glcm_feat = glcm_features(img)\n",
    "            lbp_feat = lbp_features(img)\n",
    "\n",
    "            combined_features = np.concatenate([dwt_feat, glcm_feat, lbp_feat])\n",
    "            features.append(combined_features)\n",
    "            labels.append(label.item())\n",
    "\n",
    "    return np.array(features), np.array(labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Özellik çıkarma: Eğitim ve test veri seti\n",
    "train_features, train_labels = extract_features(train_loader)\n",
    "test_features, test_labels = extract_features(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA ile boyut küçültme\n",
    "pca = PCA(n_components=500)\n",
    "train_features_pca = pca.fit_transform(train_features)\n",
    "test_features_pca = pca.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA ile boyut küçültme\n",
    "pca = PCA(n_components=1024)\n",
    "train_features_pca2 = pca.fit_transform(train_features)\n",
    "test_features_pca2= pca.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=300)\n",
    "train_features_pca_3 = pca.fit_transform(train_features)\n",
    "test_features_pca_3 = pca.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=128)\n",
    "train_features_pca_4 = pca.fit_transform(train_features)\n",
    "test_features_pca_4 = pca.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.65      0.69       937\n",
      "           1       0.76      0.89      0.82      1029\n",
      "           2       0.91      0.87      0.89      1034\n",
      "\n",
      "    accuracy                           0.81      3000\n",
      "   macro avg       0.81      0.80      0.80      3000\n",
      "weighted avg       0.81      0.81      0.81      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=400,criterion='gini',random_state=48)\n",
    "rf.fit(train_features_pca,train_labels)\n",
    "# Test doğruluğu\n",
    "test_predictions = rf.predict(test_features_pca)\n",
    "print(classification_report(test_labels, test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.62      0.66       937\n",
      "           1       0.75      0.87      0.81      1029\n",
      "           2       0.90      0.85      0.87      1034\n",
      "\n",
      "    accuracy                           0.79      3000\n",
      "   macro avg       0.79      0.78      0.78      3000\n",
      "weighted avg       0.79      0.79      0.78      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=400,criterion='gini',random_state=48)\n",
    "rf.fit(train_features_pca2,train_labels)\n",
    "# Test doğruluğu\n",
    "test_predictions = rf.predict(test_features_pca2)\n",
    "print(classification_report(test_labels, test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.66      0.71       937\n",
      "           1       0.77      0.90      0.83      1029\n",
      "           2       0.91      0.88      0.89      1034\n",
      "\n",
      "    accuracy                           0.82      3000\n",
      "   macro avg       0.82      0.81      0.81      3000\n",
      "weighted avg       0.82      0.82      0.81      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=400,criterion='gini',random_state=48)\n",
    "rf.fit(train_features_pca_3,train_labels)\n",
    "# Test doğruluğu\n",
    "test_predictions = rf.predict(test_features_pca_3)\n",
    "print(classification_report(test_labels, test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.68      0.73       937\n",
      "           1       0.79      0.91      0.85      1029\n",
      "           2       0.91      0.89      0.90      1034\n",
      "\n",
      "    accuracy                           0.83      3000\n",
      "   macro avg       0.83      0.83      0.83      3000\n",
      "weighted avg       0.83      0.83      0.83      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=400,criterion='gini',random_state=48)\n",
    "rf.fit(train_features_pca_4,train_labels)\n",
    "# Test doğruluğu\n",
    "test_predictions = rf.predict(test_features_pca_4)\n",
    "print(classification_report(test_labels, test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
